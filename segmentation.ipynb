{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzlUa38KcXjBKJ0L5/ElPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goelpravin/practice/blob/master/segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEXO2tcI5AvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "7d351262-977a-481c-ebd2-062d355df106"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git\n",
        "!pip install -U tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/examples.git\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-2rx8t4zv\n",
            "  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-2rx8t4zv\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===fa50f88293ef253803c7fcf1ea9c562f27e58656-) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===fa50f88293ef253803c7fcf1ea9c562f27e58656-) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-examples\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-examples: filename=tensorflow_examples-fa50f88293ef253803c7fcf1ea9c562f27e58656_-cp36-none-any.whl size=135402 sha256=15861f82572003145a25209e90ff8522576b58f99d1db75d6172f0cee8abc07a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f3c1zvxc/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d\n",
            "Successfully built tensorflow-examples\n",
            "Installing collected packages: tensorflow-examples\n",
            "Successfully installed tensorflow-examples-fa50f88293ef253803c7fcf1ea9c562f27e58656-\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/06/5886551edf8b6791ce920ee531ceeeafe071a99ddaa6d77d3cf5fb66e0a6/tfds_nightly-3.2.1.dev202008110106-py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.22.2)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/03/0f9595c0c2ef12590877f3c47e5f579759ce5caf817f8256d5dcbd8a1177/importlib_resources-3.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.1.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly) (1.52.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly) (3.1.0)\n",
            "Installing collected packages: importlib-resources, tfds-nightly\n",
            "Successfully installed importlib-resources-3.0.0 tfds-nightly-3.2.1.dev202008110106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M33WCKcnGWAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "90722b43-d75d-4714-cbc1-d20d133119a6"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset oxford_iiit_pet/3.2.0 (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteNSJF90/oxford_iiit_pet-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteNSJF90/oxford_iiit_pet-test.tfrecord\n",
            "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2dFzmr5JKP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def getImageMask(datapoint):\n",
        "  image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "  return tf.expand_dims(image, axis=0), tf.expand_dims(mask, axis=0)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqwDqeQrwle-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_preprocessing.image import NumpyArrayIterator\n",
        "def tfds_imgen_train(ds, imgen,maskgen, batch_size):\n",
        "  # Provide the same seed and keyword arguments to the fit and flow methods\n",
        "  seed = 1\n",
        "  \n",
        "  for images, segmentation_masks in ds:\n",
        "    #print(\"labels in tfdsimgen train\",segmentation_masks)\n",
        "    imgen.fit(images, augment=True, seed=seed)\n",
        "    maskgen.fit(segmentation_masks, augment=True, seed=seed)\n",
        "    image_generator = imgen.flow(\n",
        "        x=images,\n",
        "        seed=seed)\n",
        "    mask_generator = maskgen.flow(\n",
        "        x=segmentation_masks,\n",
        "        seed=seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    return train_generator\n",
        "    print(\"image\",image_generator.shape)\n",
        "    print(\"mask\",mask_generator.shape)\n",
        "    #yield image_generator, mask_generator\n",
        "    #return (NumpyArrayIterator(images,segmentation_masks,imgen,batch_size=batch_size))\n",
        "    #return_value = next( imgen.flow(x=images, y=labels, batch_size=batch_size))\n",
        "    #print(return_value)\n",
        "    #yield return_value\n",
        "def tfds_imgen_validate(ds, imgen, maskgen,batch_size):\n",
        "  # Provide the same seed and keyword arguments to the fit and flow methods\n",
        "  seed = 2\n",
        "  \n",
        "  for images, labels in ds:\n",
        "    print(\"labels in tfdsimgen validate\",labels)\n",
        "    imgen.fit(images, augment=True, seed=seed)\n",
        "    maskgen.fit(labels, augment=True, seed=seed)\n",
        "    image_generator = next(imgen.flow(\n",
        "        x=images,\n",
        "        seed=seed))\n",
        "    mask_generator = next(maskgen.flow(\n",
        "        x=labels,\n",
        "        seed=seed))\n",
        "    #zipped_generator = zip(image_generator, mask_generator)\n",
        "    #yield image_generator, mask_generator\n",
        "    return (NumpyArrayIterator(images,labels,imgen))\n",
        "    #return_value = next( imgen.flow(x=images, y=labels, batch_size=batch_size))\n",
        "    #print(return_value)\n",
        "    #yield return_value\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH9PfKu9HdKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "459eb45a-7712-4536-90b0-b0e43346a7e3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "train_ds = dataset['train'].map(getImageMask)\n",
        "test_ds = dataset['test'].map(getImageMask)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1/255)#,\n",
        "      #rotation_range=40,\n",
        "      #width_shift_range=0.2,\n",
        "      #height_shift_range=0.2,\n",
        "      #shear_range=0.2,\n",
        "      #zoom_range=0.2,\n",
        "      #horizontal_flip=True,\n",
        "      #fill_mode='nearest')\n",
        "# we create two instances with the same arguments\n",
        "train_data_gen_args = dict(featurewise_center=True,\n",
        "                     featurewise_std_normalization=True,\n",
        "                     rotation_range=40,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2)\n",
        "train_image_datagen = ImageDataGenerator(**train_data_gen_args)\n",
        "train_mask_datagen = ImageDataGenerator(**train_data_gen_args)\n",
        "\n",
        "validation_image_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_mask_datagen = ImageDataGenerator(rescale=1/255)\n",
        "batch_size_training = 128\n",
        "batch_size_validation = 32\n",
        "train_generator = tfds_imgen_train(train_ds.as_numpy_iterator(),train_image_datagen,train_mask_datagen,batch_size_training)\n",
        "validation_generator = tfds_imgen_validate(test_ds.as_numpy_iterator(),validation_image_datagen,validation_mask_datagen,batch_size_validation)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels in tfdsimgen validate [[[[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]\n",
            "   [2.]\n",
            "   ...\n",
            "   [2.]\n",
            "   [2.]\n",
            "   [2.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GlsJQ6TLLHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      #display([tf.squeeze(image[0],axis=0), tf.squeeze(mask[0],axis=0), create_mask(pred_mask)])\n",
        "      display(image, mask, create_mask(pred_mask))\n",
        "  else:\n",
        "    for image, mask in train_ds.take(1):\n",
        "      img2predict, mask2predict = image, mask\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(img2predict))])\n",
        "             #create_mask(model.predict(sample_image))])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCk8vE-oLBOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  print(\"pred mask\",pred_mask)\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q711PoQOLSYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    #print(display_list[i])\n",
        "\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "for image, mask in train_ds.take(1):\n",
        "  sample_image, sample_mask = tf.squeeze(image,axis=0), tf.squeeze(mask,axis=0)\n",
        "#display([sample_image, sample_mask])\n",
        "#show_predictions()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJmBjc5z0JTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "11c881d1-8206-4122-d276-6a9c41532b9a"
      },
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "OUTPUT_CHANNELS = 3\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "def compute_loss(labels, predictions):\n",
        "  print(\"labels=\",labels)\n",
        "  print(\"predictions=\",predictions)\n",
        "  per_example_loss = loss_object(labels, predictions)\n",
        "  #per_example_loss /= tf.cast(\n",
        "   #   tf.shape(labels)[1] * tf.shape(labels)[2], tf.float32)  # <--- See if this fixes the NaNs.\n",
        "  return tf.nn.compute_average_loss(per_example_loss)\n",
        "      #per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]\n",
        "\n",
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "print(\"test\")\n",
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              loss=compute_loss,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PUEVqCY0dxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "e9246793-35c4-4f55-eee7-1c7fe768aeac"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "class myCallback (tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    if(logs.get('accuracy')>0.8):\n",
        "      print(\"\\nReached 80% accuracy, so stopping further epochs\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "\n",
        "\n",
        "num_training_images = info.splits['train'].num_examples\n",
        "epoch_steps = num_training_images/batch_size_training\n",
        "\n",
        "num_testing_images = info.splits['test'].num_examples\n",
        "validation_steps = num_testing_images/batch_size_validation\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=epoch_steps,  \n",
        "      epochs=10,\n",
        "      verbose=2,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=validation_steps,\n",
        "      callbacks=[callbacks])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "labels= Tensor(\"IteratorGetNext:1\", shape=(None, None, None, None), dtype=float32)\n",
            "predictions= Tensor(\"functional_7/conv2d_transpose_9/BiasAdd:0\", shape=(None, 128, 128, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-92564462345a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       callbacks=[callbacks])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-20-4ecc903bf68b>:12 compute_loss  *\n        return tf.nn.compute_average_loss(per_example_loss)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:428 compute_average_loss\n        with losses_util.check_per_example_loss_rank(per_example_loss):\n    /usr/lib/python3.6/contextlib.py:81 __enter__\n        return next(self.gen)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/util.py:163 check_per_example_loss_rank\n        \"at least rank 1, received: {}\".format(per_example_loss))\n\n    ValueError: Invalid value passed for `per_example_loss`. Expected a tensor with at least rank 1, received: Tensor(\"compute_loss/sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybMhPvQsP4br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bca17d3-d56f-46a3-b370-51b5ea680d31"
      },
      "source": [
        "show_predictions(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred mask [[[[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]\n",
            "\n",
            "  [[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]\n",
            "\n",
            "  [[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]\n",
            "\n",
            "  [[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]\n",
            "\n",
            "  [[nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   ...\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]\n",
            "   [nan nan nan]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-d5cb1be63b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-347a484ab172>\u001b[0m in \u001b[0;36mshow_predictions\u001b[0;34m(dataset, num)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m#display([tf.squeeze(image[0],axis=0), tf.squeeze(mask[0],axis=0), create_mask(pred_mask)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: display() takes 1 positional argument but 3 were given"
          ]
        }
      ]
    }
  ]
}